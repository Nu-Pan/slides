# 最近の GPGPU
in beer bash 2017/8/XX

---
# お品書き

---
## お品書き
- 前半（概要）
 - GPGPU について
 - GPGPUするなら
- 後半（トピック）
 - GPU クラウド
 - ディープラーニング
 - 量子コンピューティング

---
# はじめに

---
## なんで GPU ？
- ムーアの法則
- CPU はもう頭打ち
- GPU はまだ望みがある

---
## タダ乗りしたい！
- なんでも GPU で実行できるのか？
- そもそも言うほどすごいのか？

---
## タダ乗りしたい！
- なんでもは出来ないです
- でもマッチする問題ではすごい性能を発揮
- そういうお話をします！

---
# What is GPGPU

---
## What is GPGPU
- `G`eneral-`p`urpose computing on `g`raphics `p`rocessing `u`nits
- GPU を汎用的にいろんな計算に使いますよ、ということ
- グラフィックスと全然関係無いことにも使える

---
## CPU じゃダメなのか？
- CPU だと遅い処理があったとき
- GPU にやらせると爆速（になることがある）

---
## どのくらい速いのか？
- 論文の最後に GPGPU という呪文を書くのが横行するくらい
- future work にGPGPU で高速化って書く
- （僕も書いた気がします…）

---
## ネットに上がっていたベンチ
- TensorFlow のデモで計測
- CPU も GPU も当時のハイエンド

︙

### CPU の 20 倍！

---
## ネットに上がっていたベンチ
- 計測時の環境は
  - core i7 6700K(skylake)
  - geForce GTX 980(Maxwell)
- 当時の最高モデルで理論値を比べると...

| 製品名 | 個数 | TFLOPS | 倍率 |
| :-- | :-- | :-- | :-- |
| GTX 980 | 1 | 5 | x1 |
| TESLA M40 | 1 | 7 | x1.4 |
| core i7 6700K | 1 | 0.1 | x1 |
| Xeon E7-8857 v2 | 8 | 4 | x40 |

---
## ネットに上がっていたベンチ
| 製品名 | 個数 | TFLOPS | 倍率 |
| :-- | :-- | :-- | :-- |
| GTX 980 | 1 | 5 | x1 |
| TESLA M40 | 1 | 7 | x1.4 |
| core i7 6700K | 1 | 0.1 | x1 |
| Xeon E7-8857 v2 | 8 | 4 | x40 |

- FLOPS の理論値的には GPU の方が優位
- しかも GPU はまだ何枚か挿せるし
- とにかく事実として GPU は速い

---
# GPU クラウド

---
## 計算資源を金で買う
- 時間単位とか年単位とかでクラウド上の GPU を借りることができる
  - １時間あたり１ドル前後
  - Tesla を積んだマシンを借りることができる
- 各社提供中
  - Amazon Web Service
  - Microsoft Azure
  - Google Compute Engine
  - さくら「高火力コンピューティング」

---
## 使い方
- docker コンテナ作ってサービスに投げる
- 個人ユースだと
  - 自宅の GPU で少し実験
  - 本番は GPU クラウドで実行
- 企業ユースだと
  - 年契約して常に GPU をぶん回す

---
# ディープラーニング

---
## ディープラーニング
- とにかくディープラーニングが最大のトピック
- 実際は DL 以外にも重要な応用はあるのだけど…

---
## なんでディープラーニング？
- いろんなことが噛み合った
- すでに GPGPU 前提みたいな事になっている
 - （他にもあるのだけど…）

---
## 何が噛み合った？
- GPU でやると速くなる典型例だった
  - 基本は数百次元のベクトルの演算
  - それをひたすら繰り返す
  - 必要な計算量が膨大かつ並列性が高い
- 途方もない需要があった
  - とにかく学習に時間がかかる
  - そのくせトライ＆エラーが必須
  - 素早く結果を出さないと競争に勝てない

### 相性が良かったし需要もあった

---
## nVidia volta 世代
- 次世代の GPU
- AI がメイントピック

---
## CUDA9
- volta サポートがメイントピック
- volta の新機能を使えるようになる
- テンソルコアが最重要トピック
 - 機械学習が加速する！

---
## Tensor Core
- $4{\times}4$ の行列の積と和
$${\boldsymbol D} = {\boldsymbol A} {\times} {\boldsymbol B} + {\boldsymbol C}$$
- 行列に特殊化した積和演算という趣
  - 従来の積和演算命令が扱うのはスカラー値
  - 扱う対象を行列演算に拡張した

---
## Tensor Core
- $4{\times}4$ の行列の積と和
$${\boldsymbol D} = {\boldsymbol A} {\times} {\boldsymbol B} + {\boldsymbol C}$$
- そのほか
  - 16bit FP で入力
  - 32bit FP で出力
  - 精度混合型の融合積和演算(FMA)
  - 実行は２クロック

---
## Tensor Core
- $4{\times}4$ で十分？
  - 巨大な行列演算は小さい行列演算の組み合わせ
  - 小さいサイズでも行列演算を高速にできれば OK
  - テンソルの階数が増えても同じ

---
## Tensor Core
- なんと脅威の 120 TFLOPS
  - すべて Tensor Core で演算した場合の話
  - ぶっちゃけ眉唾である
- 参考
 - 地球シミュレータ（第二世代） : 122 TFLOPS(2009年で世界16位)
 - 神威太湖之光 : 93.01PFLOPS(現行世界１位)

---
## What is Tensor Core
- ハード的には
  - StreamingMultiprocessor 内にいる
  - 浮動小数点演算ユニットと同じ階層にいる

[公式](https://devblogs.nvidia.com/parallelforall/inside-volta/) の出しているダイアグラムで見ると…。

---?image=assets/v100_whole_diagram.gif&size=contain

---?image=assets/v100_sm_diagram.gif&size=contain

---
# 量子コンピューティング

---
## ライバルは量子コンピューティング？
- D-Wave 2x のこと
- GPU と得意分野が被ってる！
- 適用可能な問題で恐ろしい速度を発揮
  - ベンチマークでのはなし
  - geForce GTX 1080 の１万倍（！）

---
## とはいえ
- 有効な問題が限られている
  - 数値最適化問題
  - 組み合わせ最適化問題
- 汎用的なコンピューターではない
  - CPU, GPU の完全な置き換えではない
- なんで？
  - 量子アニーリング（量子焼きなまし法）方式
  - 焼きなまし法 = 一般的なアルゴリズム
  - 物理現象で焼きなまし法を実行

---
## 具体的に解ける問題
- 巡回セールスマン問題
  - 組合せ最適化問題
  - すべてのチェックポイントを１度づつ回る
  - ただし、総移動時間を最小化する
- 深層学習
  - またおまえか
  - 数値最適化問題
  - 学習 -> 確率的勾配法 -> 焼きなまし法

---
## まとめ
- GPU はマッチすれば凄く速い！
- ハードウェアレベルで深層学習の方を向いている
- 競合する新しいコンピューターも出てきてる

---
# おしまい

---
## リンク
- [CUDAとOpenCLどっちがいいの？ - Qiita](http://qiita.com/aokomoriuta/items/777f00f4d9f2bec887ba)
- [D-Wave、”GeForce GTX 1080比で1万倍高速“な量子コンピュータ「D-Wave 2000Q」 ～量子ビット数が前製品から2倍に - PC Watch](http://pc.watch.impress.co.jp/docs/news/1040817.html)
- [NVIDIA Deep Learning Institute 2017 基調講演](https://www.slideshare.net/NVIDIAJapan/nvidia-deep-learning-institute-2017)
- [インテル® Xeon® プロセッサー E7-8800 v2 ファミリー ベンチマーク結果 | HPCシステムズはすべての研究開発者に計算力を提供します。](http://www.hpc.co.jp/benchmark20150213.html)

+++
# 補足資料

---
# GPGPU するなら

---
## GPGPU 環境
- CUDA
- Compute Shader
- OpenCL
- OpenMP
- ...

いろいろある

---
## 直接触るのか？
- 直接触るのはいかにもしんどい
- 面倒を見ないといけない事が多い
- いわゆるヤクの毛刈り状態になりがち

---
## 例えば CUDA だと…
- 専用の言語にアルゴリズムを書き下す
- C++ から呼べるように中継関数を用意する
- makefile に手を入れて .cu もコンパイルできるようにする
- メインメモリ <-> VRAM 間のデータ UL / DL を計算の前後に呼ぶ
- スループットが出ないので処理を非同期化する
- GPU のお気持ちを汲み取ってチューニング

### やってられない！

---
## なので
- GPU サポートのライブラリを使う
- 直接 CUDA コードを書くよりも圧倒的にマシ

---
## 特に行列ベクトル演算
- 行列ベクトルで書ける問題は GPU 向き
- cublas とか cupy とかそういうのを使う

---
## 業界標準ライブラリ
- GPU と親和性の高い界隈だと GPU サポートは割りと当たり前
- 画像処理なら OpenCV とか
- 深層学習なら TensorFlow とか

---
## 個人でも試せます
- グラフィックスカードさえあれば！
- CUDA がとっつきやすい(nVidia 限定ですが)
- 直接触らなくても恩恵には預かれます

---
# CPU vs. GPU

---
## コアが違う
- CPU
  - １コア内での複雑なプログラムも効率的に実行
  - 全てのコアで別々の事をする
  - コアは数個
- GPU
  - １コア内での複雑な計算は向いていない
  - 全てのコアで同じことをする
  - コアは数百個

---
## 並列度のオーダーが違う
例えば、100万個の相互に独立なタスクがあったら…
- CPU
  - 8 スレッド立ててタスクを分配する
  - 各スレッドではタスクを直列に処理
- GPU
  - 100万個スレッドを立てる
  - １スレッドで１タスクだけ処理

---
## メモリが違う
HDD からデータをロードして処理しようと思ったら
- CPU
  - HDD -> メインメモリ のロードだけで OK
- GPU
  - HDD -> メインメモリ -> VRAM の転送が必要
  - メモリを共用していればその限りではない

---
## メモリが違う
- CPU
  - DDR
  - ランダムアクセスでもそれなりに速い
- GPU
  - GDDR
  - ランダムアクセスはそれほど早くない

---
# GPU の得手不得手

---
## 得意なこと
- １つ１つのタスクが
  - 複雑な事をしない（制御構文とか）
  - 複雑なデータ IO をしない
- データ帯域幅 << 計算量
  - 収束するまで反復計算するようなの
  - データ転送は最初と最後だけ

---
## 苦手なこと
- 複雑なアルゴリズム
- データ入出力の帯域幅が広い
- データアクセスがランダムかつ大量

---
# 積和演算

---
## 積和演算
- 積と和を位置命令で行う
  - $d = a \times b + c$
  - 演算対象は FP32 とかのスカラー値
- 科学計算で頻発する
  - 行列の積がまさにそう
  - 行列の積は内積のくりかえし
  - 内積はスカラーの積を１つのスカラーに足し込む演算
  - それってつまり積和演算
- FMA それ自体は
  - CPU でも拡張命令として存在する
  - volta 以前の CUDA でもそう

---
# 量子コンピューティング

---
## ちなみに
- 量子焼きなまし法は
  - 局所解にはまる
  - 絶対零度まで冷却する必要がある
- レーザーネットワーク方式だと
  - 大域的最適化を見つけられる
  - 絶対零度まで冷却しなくていい

---
## ついでに
- 量子コンピューターもクラウド化しているとか
- 一部にのみ公開されているとか
- 量子コンピューティング用の言語を使うらしい

---
# gitpitch

---
## gitpitch
- このスライドは gitpitch で書いてます
- markdown でサクっと作れてステキ！
- 個人的には LaTeX + beamer と比べてだいぶ楽
- ただ、既存のスライド系ツールとはちょっと感覚が違う

---
## アルファベット圏前提
- 「スペースで改行する」が前提な感じはある
- 自動版組系にありがちではあるけど…。
- スペースが入らない日本語だと改行が微妙
- 英語なら適当に改行されてもまぁそれっぽく見える
